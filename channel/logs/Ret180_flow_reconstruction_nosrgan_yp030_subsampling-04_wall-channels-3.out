2021-02-17 11:33:10.383278: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-17 11:33:16.503538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-02-17 11:33:17.617858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:17.620638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-02-17 11:33:17.620782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-17 11:33:17.663871: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-17 11:33:17.708968: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-02-17 11:33:17.727245: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-17 11:33:17.791425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-02-17 11:33:17.804042: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-17 11:33:17.847463: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-17 11:33:17.847647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:17.848628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:17.849487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
Using TensorFlow version:  2.3.0 , GPU: 1
Using Keras version:  2.4.0
2021-02-17 11:33:18.090431: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499965000 Hz
2021-02-17 11:33:18.092114: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x427ae00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-02-17 11:33:18.092149: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-02-17 11:33:18.217169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:18.218287: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x42e7240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-02-17 11:33:18.218375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2021-02-17 11:33:18.218855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:18.220166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-02-17 11:33:18.220224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-17 11:33:18.220271: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-17 11:33:18.220324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-02-17 11:33:18.220359: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-17 11:33:18.220391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-02-17 11:33:18.220424: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-17 11:33:18.220457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-17 11:33:18.220566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:18.221876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:18.223143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-02-17 11:33:18.223209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-17 11:33:19.565976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-17 11:33:19.566060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-02-17 11:33:19.566073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-02-17 11:33:19.566324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:19.568151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-17 11:33:19.569197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10068 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)
The inputs are normalized to have a unit Gaussian distribution
Model: "CNN-POD"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
high-res-input (InputLayer)  [(None, 3, 48, 48)]       0         
_________________________________________________________________
predic_01 (Conv2D)           (None, 128, 48, 48)       9728      
_________________________________________________________________
predic_02 (BatchNormalizatio (None, 128, 48, 48)       512       
_________________________________________________________________
predic_03 (MaxPooling2D)     (None, 128, 24, 24)       0         
_________________________________________________________________
predic_04 (Conv2D)           (None, 256, 24, 24)       295168    
_________________________________________________________________
predic_05 (BatchNormalizatio (None, 256, 24, 24)       1024      
_________________________________________________________________
predic_06 (MaxPooling2D)     (None, 256, 12, 12)       0         
_________________________________________________________________
predic_07 (Conv2D)           (None, 256, 12, 12)       590080    
_________________________________________________________________
predic_08 (BatchNormalizatio (None, 256, 12, 12)       1024      
_________________________________________________________________
predic_10 (Conv2D)           (None, 512, 12, 12)       1180160   
_________________________________________________________________
predic_11 (BatchNormalizatio (None, 512, 12, 12)       2048      
_________________________________________________________________
predic_13 (Conv2D)           (None, 512, 12, 12)       2359808   
_________________________________________________________________
predic_14 (BatchNormalizatio (None, 512, 12, 12)       2048      
_________________________________________________________________
predic_15 (Conv2D)           (None, 64, 12, 12)        294976    
=================================================================
Total params: 4,736,576
Trainable params: 4,733,248
Non-trainable params: 3,328
_________________________________________________________________
None
2021-02-17 11:33:41.711124: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 1834 of 4200
2021-02-17 11:33:51.765481: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 3715 of 4200
2021-02-17 11:33:54.214705: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.
2021-02-17 11:33:56.043474: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-17 11:33:59.772328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-17 11:37:43.023091: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 1770 of 4200
2021-02-17 11:37:53.022363: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 3889 of 4200
2021-02-17 11:37:54.707436: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.
Epoch 0001/0020, loss: 6.716580867767334, val_loss: 2.226757049560547, elapsed time from start: 298.4498598575592
2021-02-17 11:41:21.499676: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 1706 of 4200
2021-02-17 11:41:31.496293: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 3556 of 4200
2021-02-17 11:41:34.822910: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.
Epoch 0002/0020, loss: 0.9788909554481506, val_loss: 0.325688898563385, elapsed time from start: 520.256147146225
Epoch 0003/0020, loss: 0.15599362552165985, val_loss: 0.066721610724926, elapsed time from start: 620.6090216636658
Epoch 0004/0020, loss: 0.042370665818452835, val_loss: 0.029890064150094986, elapsed time from start: 720.2138528823853
Epoch 0005/0020, loss: 0.024718906730413437, val_loss: 0.02270941622555256, elapsed time from start: 818.5089199542999
Epoch 0006/0020, loss: 0.021292049437761307, val_loss: 0.021533403545618057, elapsed time from start: 920.311304807663
Epoch 0007/0020, loss: 0.02046818472445011, val_loss: 0.021056493744254112, elapsed time from start: 1018.7158312797546
Epoch 0008/0020, loss: 0.020115962252020836, val_loss: 0.020815327763557434, elapsed time from start: 1120.7742238044739
Epoch 0009/0020, loss: 0.01989031583070755, val_loss: 0.0206198338419199, elapsed time from start: 1222.1260907649994
Epoch 0010/0020, loss: 0.019716475158929825, val_loss: 0.020492253825068474, elapsed time from start: 1321.9416127204895
Epoch 0011/0020, loss: 0.01957450807094574, val_loss: 0.02030409313738346, elapsed time from start: 1420.2648949623108
Epoch 0012/0020, loss: 0.019382022321224213, val_loss: 0.020250067114830017, elapsed time from start: 1523.5065009593964
Epoch 0013/0020, loss: 0.019209494814276695, val_loss: 0.020125258713960648, elapsed time from start: 1622.3472073078156
Epoch 0014/0020, loss: 0.019064730033278465, val_loss: 0.01990978606045246, elapsed time from start: 1723.6613368988037
Epoch 0015/0020, loss: 0.018936919048428535, val_loss: 0.019816089421510696, elapsed time from start: 1822.1962931156158
Epoch 0016/0020, loss: 0.018820257857441902, val_loss: 0.019677085801959038, elapsed time from start: 1925.3318610191345
Epoch 0017/0020, loss: 0.018725359812378883, val_loss: 0.019634857773780823, elapsed time from start: 2024.2205357551575
Epoch 0018/0020, loss: 0.01863093674182892, val_loss: 0.019551925361156464, elapsed time from start: 2122.3367846012115
Epoch 0019/0020, loss: 0.01854304037988186, val_loss: 0.019494226202368736, elapsed time from start: 2225.804696559906
Epoch 0020/0020, loss: 0.018467312678694725, val_loss: 0.019402170553803444, elapsed time from start: 2324.924518585205
WARNING:tensorflow:From /home/alejandro/projects/urban-flows/.env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-02-17 12:12:19.704267: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /home/alejandro/projects/urban-flows/.env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.

2021-02-06 10:32:19.845685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-06 10:32:30.234591: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-02-06 10:32:30.660742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:30.661649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-02-06 10:32:30.661681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-06 10:32:31.220893: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-06 10:32:31.489766: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-02-06 10:32:31.538436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-06 10:32:32.150912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-02-06 10:32:32.197216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-06 10:32:33.317235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-06 10:32:33.317439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:33.318569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:33.322949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
Using TensorFlow version:  2.3.0 , GPU: 1
Using Keras version:  2.4.0
2021-02-06 10:32:33.800498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499980000 Hz
2021-02-06 10:32:33.803564: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x51ed2e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-02-06 10:32:33.803602: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-02-06 10:32:34.255063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:34.256184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5259720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-02-06 10:32:34.256219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2021-02-06 10:32:34.344972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:34.349694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-02-06 10:32:34.349764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-06 10:32:34.349828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-06 10:32:34.349870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-02-06 10:32:34.349897: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-06 10:32:34.349922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-02-06 10:32:34.349947: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-06 10:32:34.349972: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-06 10:32:34.350051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:34.351057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:34.351997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-02-06 10:32:34.402789: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-06 10:32:39.891688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-06 10:32:39.891759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-02-06 10:32:39.891774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-02-06 10:32:39.912970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:39.916035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-06 10:32:39.917042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10068 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)
The inputs are normalized to have a unit Gaussian distribution
Model: "CNN-POD"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
high-res-input (InputLayer)  [(None, 3, 192, 192)]     0         
_________________________________________________________________
predic_01 (Conv2D)           (None, 128, 192, 192)     9728      
_________________________________________________________________
predic_02 (BatchNormalizatio (None, 128, 192, 192)     512       
_________________________________________________________________
predic_03 (MaxPooling2D)     (None, 128, 96, 96)       0         
_________________________________________________________________
predic_04 (Conv2D)           (None, 256, 96, 96)       295168    
_________________________________________________________________
predic_05 (BatchNormalizatio (None, 256, 96, 96)       1024      
_________________________________________________________________
predic_06 (MaxPooling2D)     (None, 256, 48, 48)       0         
_________________________________________________________________
predic_07 (Conv2D)           (None, 256, 48, 48)       590080    
_________________________________________________________________
predic_08 (BatchNormalizatio (None, 256, 48, 48)       1024      
_________________________________________________________________
predic_09 (MaxPooling2D)     (None, 256, 24, 24)       0         
_________________________________________________________________
predic_10 (Conv2D)           (None, 512, 24, 24)       1180160   
_________________________________________________________________
predic_11 (BatchNormalizatio (None, 512, 24, 24)       2048      
_________________________________________________________________
predic_12 (MaxPooling2D)     (None, 512, 12, 12)       0         
_________________________________________________________________
predic_13 (Conv2D)           (None, 512, 12, 12)       2359808   
_________________________________________________________________
predic_14 (BatchNormalizatio (None, 512, 12, 12)       2048      
_________________________________________________________________
predic_15 (Conv2D)           (None, 64, 12, 12)        294976    
=================================================================
Total params: 4,736,576
Trainable params: 4,733,248
Non-trainable params: 3,328
_________________________________________________________________
None
2021-02-06 10:33:00.002154: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 1884 of 4200
2021-02-06 10:33:09.973393: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 4003 of 4200
2021-02-06 10:33:10.909591: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.
2021-02-06 10:33:12.730217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-06 10:33:21.078934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-06 10:37:09.332239: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 1994 of 4200
2021-02-06 10:37:19.365938: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 4085 of 4200
2021-02-06 10:37:19.904322: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.
Epoch 0001/0030, loss: 6.686551570892334, val_loss: 2.22331166267395, elapsed time from start: 309.4564311504364
2021-02-06 10:38:08.726414: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 3665 of 4200
2021-02-06 10:38:09.915916: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.
2021-02-06 10:41:59.347345: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 1985 of 4200
2021-02-06 10:42:09.301311: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 4086 of 4200
2021-02-06 10:42:09.832190: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.
Epoch 0002/0030, loss: 0.9747116565704346, val_loss: 0.32132530212402344, elapsed time from start: 599.3654832839966
Epoch 0003/0030, loss: 0.15102563798427582, val_loss: 0.060664210468530655, elapsed time from start: 853.6003530025482
Epoch 0004/0030, loss: 0.03625496104359627, val_loss: 0.023714514449238777, elapsed time from start: 1107.2621867656708
Epoch 0005/0030, loss: 0.01773061975836754, val_loss: 0.015843482688069344, elapsed time from start: 1359.9463412761688
Epoch 0006/0030, loss: 0.014653827995061874, val_loss: 0.014689728617668152, elapsed time from start: 1613.3057634830475
Epoch 0007/0030, loss: 0.01402607373893261, val_loss: 0.014351735822856426, elapsed time from start: 1865.7985446453094
Epoch 0008/0030, loss: 0.013761229813098907, val_loss: 0.01452141534537077, elapsed time from start: 2118.072342634201
Epoch 0009/0030, loss: 0.01359669491648674, val_loss: 0.01418287307024002, elapsed time from start: 2370.094674348831
Epoch 0010/0030, loss: 0.013472664169967175, val_loss: 0.013973817229270935, elapsed time from start: 2623.4419214725494
Epoch 0011/0030, loss: 0.013377495110034943, val_loss: 0.014321714639663696, elapsed time from start: 2877.0391614437103
Epoch 0012/0030, loss: 0.013228152878582478, val_loss: 0.013577545993030071, elapsed time from start: 3130.243579864502
Epoch 0013/0030, loss: 0.013103175908327103, val_loss: 0.013540763407945633, elapsed time from start: 3383.156461954117
Epoch 0014/0030, loss: 0.012993115931749344, val_loss: 0.013308348134160042, elapsed time from start: 3636.6531586647034
Epoch 0015/0030, loss: 0.012895707041025162, val_loss: 0.013318927958607674, elapsed time from start: 3891.699319124222
Epoch 0016/0030, loss: 0.012812519446015358, val_loss: 0.01327434554696083, elapsed time from start: 4146.168530225754
Epoch 0017/0030, loss: 0.01274076383560896, val_loss: 0.013083024881780148, elapsed time from start: 4401.054429292679
Epoch 0018/0030, loss: 0.012672989629209042, val_loss: 0.013083050958812237, elapsed time from start: 4655.474228143692
Epoch 0019/0030, loss: 0.012610649690032005, val_loss: 0.012928579933941364, elapsed time from start: 4909.971913576126
Epoch 0020/0030, loss: 0.012557637877762318, val_loss: 0.013315590098500252, elapsed time from start: 5164.713107347488
Epoch 0021/0030, loss: 0.012507985346019268, val_loss: 0.01300142239779234, elapsed time from start: 5420.234461307526
Epoch 0022/0030, loss: 0.012461425736546516, val_loss: 0.012969810515642166, elapsed time from start: 5675.465423583984
Epoch 0023/0030, loss: 0.01242043450474739, val_loss: 0.012738324701786041, elapsed time from start: 5931.148331642151
Epoch 0024/0030, loss: 0.012382724322378635, val_loss: 0.012681394815444946, elapsed time from start: 6186.193203449249
Epoch 0025/0030, loss: 0.012349425815045834, val_loss: 0.012689270079135895, elapsed time from start: 6442.317536115646
Epoch 0026/0030, loss: 0.012316711246967316, val_loss: 0.012749585323035717, elapsed time from start: 6698.269341945648
Epoch 0027/0030, loss: 0.012288625352084637, val_loss: 0.012637950479984283, elapsed time from start: 6953.741051912308
Epoch 0028/0030, loss: 0.012260140851140022, val_loss: 0.0126478997990489, elapsed time from start: 7208.863653421402
Epoch 0029/0030, loss: 0.012237037532031536, val_loss: 0.012581261806190014, elapsed time from start: 7464.814916610718
Epoch 0030/0030, loss: 0.012216157279908657, val_loss: 0.012543329037725925, elapsed time from start: 7719.868401765823
WARNING:tensorflow:From /home/alejandro/projects/urban-flows/.env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-02-06 12:41:33.029045: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /home/alejandro/projects/urban-flows/.env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.

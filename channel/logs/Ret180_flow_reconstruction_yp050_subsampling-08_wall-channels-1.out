2021-02-03 20:23:34.771538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-03 20:23:40.937763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-02-03 20:23:42.121644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:42.122857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-02-03 20:23:42.122947: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-03 20:23:42.185277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-03 20:23:42.194811: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-02-03 20:23:42.223461: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-03 20:23:42.240452: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-02-03 20:23:42.252286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-03 20:23:42.319884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-03 20:23:42.320103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:42.320777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:42.321321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
Using TensorFlow version:  2.3.0 , GPU: 1
Using Keras version:  2.4.0
2021-02-03 20:23:42.420149: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500070000 Hz
2021-02-03 20:23:42.422080: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x504d2e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-02-03 20:23:42.422162: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-02-03 20:23:42.585141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:42.585932: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50b9720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-02-03 20:23:42.585963: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2021-02-03 20:23:42.586163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:42.586681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-02-03 20:23:42.586727: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-03 20:23:42.586770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-03 20:23:42.586811: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-02-03 20:23:42.586837: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-02-03 20:23:42.586861: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-02-03 20:23:42.586886: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-02-03 20:23:42.586911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-03 20:23:42.586985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:42.587531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:42.588023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-02-03 20:23:42.588063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-02-03 20:23:43.957650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-03 20:23:43.957729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-02-03 20:23:43.957745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-02-03 20:23:43.958060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:43.958675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-03 20:23:43.959217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4084 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)
The inputs are normalized to have a unit Gaussian distribution
Model: "CNN-POD"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
low-res-input (InputLayer)      [(None, 1, 24, 24)]  0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 64, 24, 24)   5248        low-res-input[0][0]              
__________________________________________________________________________________________________
p_re_lu (PReLU)                 (None, 64, 24, 24)   64          conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 64, 24, 24)   36928       p_re_lu[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 64, 24, 24)   256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
p_re_lu_1 (PReLU)               (None, 64, 24, 24)   64          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 64, 24, 24)   36928       p_re_lu_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 24, 24)   256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 64, 24, 24)   0           p_re_lu[0][0]                    
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 24, 24)   36928       add[0][0]                        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 64, 24, 24)   256         conv2d_3[0][0]                   
__________________________________________________________________________________________________
p_re_lu_2 (PReLU)               (None, 64, 24, 24)   64          batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 64, 24, 24)   36928       p_re_lu_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 64, 24, 24)   256         conv2d_4[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 64, 24, 24)   0           add[0][0]                        
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 64, 24, 24)   36928       add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 64, 24, 24)   256         conv2d_5[0][0]                   
__________________________________________________________________________________________________
p_re_lu_3 (PReLU)               (None, 64, 24, 24)   64          batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 64, 24, 24)   36928       p_re_lu_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 64, 24, 24)   256         conv2d_6[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 64, 24, 24)   0           add_1[0][0]                      
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 64, 24, 24)   36928       add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 64, 24, 24)   256         conv2d_7[0][0]                   
__________________________________________________________________________________________________
p_re_lu_4 (PReLU)               (None, 64, 24, 24)   64          batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 64, 24, 24)   36928       p_re_lu_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 64, 24, 24)   256         conv2d_8[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 64, 24, 24)   0           add_2[0][0]                      
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 64, 24, 24)   36928       add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 64, 24, 24)   256         conv2d_9[0][0]                   
__________________________________________________________________________________________________
p_re_lu_5 (PReLU)               (None, 64, 24, 24)   64          batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 64, 24, 24)   256         conv2d_10[0][0]                  
__________________________________________________________________________________________________
add_4 (Add)                     (None, 64, 24, 24)   0           add_3[0][0]                      
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 64, 24, 24)   36928       add_4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 64, 24, 24)   256         conv2d_11[0][0]                  
__________________________________________________________________________________________________
p_re_lu_6 (PReLU)               (None, 64, 24, 24)   64          batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 64, 24, 24)   256         conv2d_12[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 24, 24)   0           add_4[0][0]                      
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 24, 24)   36928       add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 64, 24, 24)   256         conv2d_13[0][0]                  
__________________________________________________________________________________________________
p_re_lu_7 (PReLU)               (None, 64, 24, 24)   64          batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 64, 24, 24)   256         conv2d_14[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 24, 24)   0           add_5[0][0]                      
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 64, 24, 24)   36928       add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 64, 24, 24)   256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
p_re_lu_8 (PReLU)               (None, 64, 24, 24)   64          batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 64, 24, 24)   256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 64, 24, 24)   0           add_6[0][0]                      
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 64, 24, 24)   36928       add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 64, 24, 24)   256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
p_re_lu_9 (PReLU)               (None, 64, 24, 24)   64          batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 64, 24, 24)   256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 64, 24, 24)   0           add_7[0][0]                      
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 64, 24, 24)   36928       add_8[0][0]                      
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 64, 24, 24)   256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
p_re_lu_10 (PReLU)              (None, 64, 24, 24)   64          batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 64, 24, 24)   256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 64, 24, 24)   0           add_8[0][0]                      
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 64, 24, 24)   36928       add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 64, 24, 24)   256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
p_re_lu_11 (PReLU)              (None, 64, 24, 24)   64          batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 64, 24, 24)   256         conv2d_22[0][0]                  
__________________________________________________________________________________________________
add_10 (Add)                    (None, 64, 24, 24)   0           add_9[0][0]                      
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 64, 24, 24)   36928       add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 64, 24, 24)   256         conv2d_23[0][0]                  
__________________________________________________________________________________________________
p_re_lu_12 (PReLU)              (None, 64, 24, 24)   64          batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 64, 24, 24)   256         conv2d_24[0][0]                  
__________________________________________________________________________________________________
add_11 (Add)                    (None, 64, 24, 24)   0           add_10[0][0]                     
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 64, 24, 24)   36928       add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 64, 24, 24)   256         conv2d_25[0][0]                  
__________________________________________________________________________________________________
p_re_lu_13 (PReLU)              (None, 64, 24, 24)   64          batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_13[0][0]                 
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 64, 24, 24)   256         conv2d_26[0][0]                  
__________________________________________________________________________________________________
add_12 (Add)                    (None, 64, 24, 24)   0           add_11[0][0]                     
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 64, 24, 24)   36928       add_12[0][0]                     
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 64, 24, 24)   256         conv2d_27[0][0]                  
__________________________________________________________________________________________________
p_re_lu_14 (PReLU)              (None, 64, 24, 24)   64          batch_normalization_26[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_14[0][0]                 
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 64, 24, 24)   256         conv2d_28[0][0]                  
__________________________________________________________________________________________________
add_13 (Add)                    (None, 64, 24, 24)   0           add_12[0][0]                     
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 64, 24, 24)   36928       add_13[0][0]                     
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 64, 24, 24)   256         conv2d_29[0][0]                  
__________________________________________________________________________________________________
p_re_lu_15 (PReLU)              (None, 64, 24, 24)   64          batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_15[0][0]                 
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 64, 24, 24)   256         conv2d_30[0][0]                  
__________________________________________________________________________________________________
add_14 (Add)                    (None, 64, 24, 24)   0           add_13[0][0]                     
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 64, 24, 24)   36928       add_14[0][0]                     
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 64, 24, 24)   256         conv2d_31[0][0]                  
__________________________________________________________________________________________________
p_re_lu_16 (PReLU)              (None, 64, 24, 24)   64          batch_normalization_30[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 64, 24, 24)   36928       p_re_lu_16[0][0]                 
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 64, 24, 24)   256         conv2d_32[0][0]                  
__________________________________________________________________________________________________
add_15 (Add)                    (None, 64, 24, 24)   0           add_14[0][0]                     
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 64, 24, 24)   36928       add_15[0][0]                     
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 64, 24, 24)   256         conv2d_33[0][0]                  
__________________________________________________________________________________________________
add_16 (Add)                    (None, 64, 24, 24)   0           p_re_lu[0][0]                    
                                                                 batch_normalization_32[0][0]     
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 256, 24, 24)  147712      add_16[0][0]                     
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 64, 48, 48)   0           conv2d_34[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu (LeakyReLU)         (None, 64, 48, 48)   0           lambda[0][0]                     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 256, 48, 48)  147712      leaky_re_lu[0][0]                
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 64, 96, 96)   0           conv2d_35[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 64, 96, 96)   0           lambda_1[0][0]                   
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 256, 96, 96)  147712      leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 64, 192, 192) 0           conv2d_36[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 64, 192, 192) 0           lambda_2[0][0]                   
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 1, 192, 192)  5185        leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
predic_01 (Conv2D)              (None, 128, 192, 192 3328        conv2d_37[0][0]                  
__________________________________________________________________________________________________
predic_02 (BatchNormalization)  (None, 128, 192, 192 512         predic_01[0][0]                  
__________________________________________________________________________________________________
predic_03 (MaxPooling2D)        (None, 128, 96, 96)  0           predic_02[0][0]                  
__________________________________________________________________________________________________
predic_04 (Conv2D)              (None, 256, 96, 96)  295168      predic_03[0][0]                  
__________________________________________________________________________________________________
predic_05 (BatchNormalization)  (None, 256, 96, 96)  1024        predic_04[0][0]                  
__________________________________________________________________________________________________
predic_06 (MaxPooling2D)        (None, 256, 48, 48)  0           predic_05[0][0]                  
__________________________________________________________________________________________________
predic_07 (Conv2D)              (None, 256, 48, 48)  590080      predic_06[0][0]                  
__________________________________________________________________________________________________
predic_08 (BatchNormalization)  (None, 256, 48, 48)  1024        predic_07[0][0]                  
__________________________________________________________________________________________________
predic_09 (MaxPooling2D)        (None, 256, 24, 24)  0           predic_08[0][0]                  
__________________________________________________________________________________________________
predic_10 (Conv2D)              (None, 512, 24, 24)  1180160     predic_09[0][0]                  
__________________________________________________________________________________________________
predic_11 (BatchNormalization)  (None, 512, 24, 24)  2048        predic_10[0][0]                  
__________________________________________________________________________________________________
predic_12 (MaxPooling2D)        (None, 512, 12, 12)  0           predic_11[0][0]                  
__________________________________________________________________________________________________
predic_13 (Conv2D)              (None, 512, 12, 12)  2359808     predic_12[0][0]                  
__________________________________________________________________________________________________
predic_14 (BatchNormalization)  (None, 512, 12, 12)  2048        predic_13[0][0]                  
__________________________________________________________________________________________________
predic_15 (Conv2D)              (None, 64, 12, 12)   294976      predic_14[0][0]                  
==================================================================================================
Total params: 6,411,905
Trainable params: 4,726,848
Non-trainable params: 1,685,057
__________________________________________________________________________________________________
None
2021-02-03 20:24:12.953330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-02-03 20:24:16.394723: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-02-03 20:24:17.193323: I tensorflow/stream_executor/cuda/cuda_driver.cc:775] failed to allocate 2.49G (2673410048 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
Epoch 0001/0030, loss: 6.68018913269043, val_loss: 2.2185394763946533, elapsed time from start: 561.5964207649231
Epoch 0002/0030, loss: 0.9726279377937317, val_loss: 0.32292696833610535, elapsed time from start: 1094.4003698825836
Epoch 0003/0030, loss: 0.15547031164169312, val_loss: 0.06949611008167267, elapsed time from start: 1627.9441306591034
Epoch 0004/0030, loss: 0.04637352377176285, val_loss: 0.03619656711816788, elapsed time from start: 2161.390055179596
Epoch 0005/0030, loss: 0.031435590237379074, val_loss: 0.031133385375142097, elapsed time from start: 2696.306168079376
Epoch 0006/0030, loss: 0.029155928641557693, val_loss: 0.030883964151144028, elapsed time from start: 3231.600931406021
Epoch 0007/0030, loss: 0.028857313096523285, val_loss: 0.03065357729792595, elapsed time from start: 3767.71195936203
Epoch 0008/0030, loss: 0.02880014479160309, val_loss: 0.030582932755351067, elapsed time from start: 4303.128686666489
Epoch 0009/0030, loss: 0.028786199167370796, val_loss: 0.030703378841280937, elapsed time from start: 4838.989166021347
Epoch 0010/0030, loss: 0.028769172728061676, val_loss: 0.03073986992239952, elapsed time from start: 4078.138396024704
Epoch 0011/0030, loss: 0.028764449059963226, val_loss: 0.030733831226825714, elapsed time from start: 4621.33011174202
Epoch 0012/0030, loss: 0.02873276360332966, val_loss: 0.03077308088541031, elapsed time from start: 5163.552842140198
Epoch 0013/0030, loss: 0.028691230341792107, val_loss: 0.030938714742660522, elapsed time from start: 5707.296067714691
Epoch 0014/0030, loss: 0.028653057292103767, val_loss: 0.03103347308933735, elapsed time from start: 6249.070249557495
Epoch 0015/0030, loss: 0.028619645163416862, val_loss: 0.0307902991771698, elapsed time from start: 6790.417793273926
Epoch 0016/0030, loss: 0.028569500893354416, val_loss: 0.03104766644537449, elapsed time from start: 7331.073620080948
Epoch 0017/0030, loss: 0.028535716235637665, val_loss: 0.031024163588881493, elapsed time from start: 7873.098057746887
Epoch 0018/0030, loss: 0.02848740853369236, val_loss: 0.031106330454349518, elapsed time from start: 8415.531572580338
Epoch 0019/0030, loss: 0.028436221182346344, val_loss: 0.03120540827512741, elapsed time from start: 8959.4987885952
Epoch 0020/0030, loss: 0.02837524749338627, val_loss: 0.031366005539894104, elapsed time from start: 9505.634026765823
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Epoch 0021/0030, loss: 0.0283293928951025, val_loss: 0.031361185014247894, elapsed time from start: 9910.015887975693
Epoch 0022/0030, loss: 0.028271321207284927, val_loss: 0.03136385232210159, elapsed time from start: 10269.55679988861
Epoch 0023/0030, loss: 0.028210751712322235, val_loss: 0.03149683400988579, elapsed time from start: 10631.28397321701
Epoch 0024/0030, loss: 0.02813877910375595, val_loss: 0.031549833714962006, elapsed time from start: 10993.490756511688
Epoch 0025/0030, loss: 0.028082624077796936, val_loss: 0.03162631765007973, elapsed time from start: 11355.527009487152
Epoch 0026/0030, loss: 0.02801043726503849, val_loss: 0.03178592398762703, elapsed time from start: 11716.87625670433
Epoch 0027/0030, loss: 0.02794269099831581, val_loss: 0.03180160000920296, elapsed time from start: 12077.01133275032
Epoch 0028/0030, loss: 0.027873102575540543, val_loss: 0.031816285103559494, elapsed time from start: 12440.519761800766
Epoch 0029/0030, loss: 0.02780221588909626, val_loss: 0.03194770961999893, elapsed time from start: 12801.445604801178
Epoch 0030/0030, loss: 0.02773957885801792, val_loss: 0.03197279945015907, elapsed time from start: 13170.869058847427
WARNING:tensorflow:From /home/alejandro/projects/urban-flows/.env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-02-03 23:09:01.258815: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /home/alejandro/projects/urban-flows/.env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
